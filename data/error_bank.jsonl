{"question": "What is gradient descent?", "model_output": "Gradient descent means the model climbs up the curve to find the peak.", "correct_output": "Gradient descent is an optimization method that updates parameters in the direction that reduces the loss function.", "error_type": ["incorrect reasoning"]}
{"question": "What is overfitting?", "model_output": "Overfitting happens when the model stops fitting the data.", "correct_output": "Overfitting occurs when a model memorizes training data and performs poorly on new, unseen data.", "error_type": ["incomplete explanation"]}
{"question": "What is cross-entropy loss?", "model_output": "Cross-entropy measures how two lines cross on a graph.", "correct_output": "Cross-entropy loss measures the difference between predicted probabilities and true labels in classification tasks.", "error_type": ["incorrect explanation"]}
{"question": "What is a neural network?", "model_output": "A neural network is a computer brain that thinks like a person.", "correct_output": "A neural network is a collection of connected layers that learn patterns in data through weighted computations.", "error_type": ["anthropomorphism"]}
{"question": "Why do we use activation functions?", "model_output": "They activate the neurons so the model wakes up.", "correct_output": "Activation functions introduce nonlinearity, allowing neural networks to model complex relationships.", "error_type": ["incorrect reasoning"]}
{"question": "What is a learning rate?", "model_output": "It is the rate at which a model learns everything perfectly.", "correct_output": "The learning rate controls the size of the parameter updates during training.", "error_type": ["overstatement"]}
{"question": "What is backpropagation?", "model_output": "It's when the model goes backwards through the dataset.", "correct_output": "Backpropagation computes gradients by propagating errors backward through the network using the chain rule.", "error_type": ["incorrect explanation"]}
{"question": "What is batch size?", "model_output": "It’s the size of the neural network's layers.", "correct_output": "Batch size is the number of samples processed before updating the model parameters.", "error_type": ["incorrect explanation"]}
{"question": "What is regularization?", "model_output": "Regularization is when you regularly train the model.", "correct_output": "Regularization techniques reduce overfitting by penalizing overly complex models.", "error_type": ["incorrect explanation"]}
{"question": "What is dropout?", "model_output": "Dropping out means deleting random data points from the dataset.", "correct_output": "Dropout randomly disables neurons during training to prevent overreliance on specific pathways and reduce overfitting.", "error_type": ["incorrect explanation"]}
{"question": "What is tokenization?", "model_output": "It converts text into tokens that are stored on a blockchain.", "correct_output": "Tokenization splits text into smaller units like words or subwords for model input.", "error_type": ["hallucination"]}
{"question": "What are embeddings?", "model_output": "Embeddings are pictures of words used by neural networks.", "correct_output": "Embeddings represent tokens as dense vectors capturing semantic relationships.", "error_type": ["incorrect explanation"]}
{"question": "What is normalization?", "model_output": "Normalization flattens all numbers to zero.", "correct_output": "Normalization rescales input features to stabilize and speed up training.", "error_type": ["incorrect reasoning"]}
{"question": "What is softmax?", "model_output": "Softmax softens the numbers so the model feels comfortable.", "correct_output": "Softmax converts logits into a probability distribution that sums to one.", "error_type": ["nonsense"]}
{"question": "What is a loss function?", "model_output": "A loss function is what the model loses when it performs badly.", "correct_output": "A loss function measures how far a model’s predictions are from the true values.", "error_type": ["incorrect reasoning"]}
{"question": "What is precision in ML?", "model_output": "Precision is how fast the model computes predictions.", "correct_output": "Precision measures the proportion of predicted positives that are actually correct.", "error_type": ["incorrect explanation"]}
{"question": "What is recall?", "model_output": "Recall is when the model calls the data back.", "correct_output": "Recall measures the proportion of actual positives that the model correctly identifies.", "error_type": ["incorrect explanation"]}
{"question": "What is an epoch?", "model_output": "An epoch is when a neural network becomes fully trained.", "correct_output": "An epoch is one full pass through the entire training dataset.", "error_type": ["incorrect reasoning"]}
{"question": "What is underfitting?", "model_output": "Underfitting is when the model fits underneath the training curve.", "correct_output": "Underfitting happens when a model is too simple to capture patterns in the data.", "error_type": ["incorrect explanation"]}
{"question": "What is a validation set?", "model_output": "A validation set validates that the dataset is correct.", "correct_output": "A validation set evaluates model performance during training to tune hyperparameters.", "error_type": ["incorrect explanation"]}
{"question": "What are parameters?", "model_output": "Parameters are the rules written into the model before training.", "correct_output": "Parameters are the learned weights and biases updated during training.", "error_type": ["incorrect explanation"]}
{"question": "What is a gradient?", "model_output": "A gradient is a graph of the model's emotions over time.", "correct_output": "A gradient represents the direction and magnitude of change needed to reduce the loss.", "error_type": ["nonsense"]}
{"question": "What is supervised learning?", "model_output": "Supervised learning is when the model supervises the data.", "correct_output": "Supervised learning uses labeled data to learn a mapping from inputs to outputs.", "error_type": ["incorrect explanation"]}
{"question": "What is unsupervised learning?", "model_output": "It's when the model learns without using any data.", "correct_output": "Unsupervised learning finds structure in unlabeled data, such as clusters or latent patterns.", "error_type": ["incorrect explanation"]}
{"question": "What is a convolution?", "model_output": "A convolution is when two datasets collide with each other.", "correct_output": "A convolution applies a sliding filter to extract spatial or temporal features from data.", "error_type": ["incorrect explanation"]}
{"question": "What is a CNN?", "model_output": "A CNN is a network that sees like a human eye.", "correct_output": "A CNN is a neural network that uses convolutional layers to extract spatial features, commonly used for images.", "error_type": ["anthropomorphism"]}
{"question": "What is an RNN?", "model_output": "An RNN is a neural network that remembers everything forever.", "correct_output": "An RNN processes sequences using hidden states that carry information across timesteps.", "error_type": ["overstatement"]}
{"question": "What is a transformer model?", "model_output": "A transformer is a machine that transforms data into something else entirely.", "correct_output": "Transformers use self-attention to model relationships between tokens and are widely used in NLP.", "error_type": ["incorrect explanation"]}
{"question": "What is self-attention?", "model_output": "Self-attention means the model looks at itself in the mirror.", "correct_output": "Self-attention lets each token attend to all other tokens to compute context-aware representations.", "error_type": ["nonsense"]}
{"question": "What is fine-tuning?", "model_output": "Fine-tuning is when you tune your laptop to run models faster.", "correct_output": "Fine-tuning adapts a pretrained model to a specific task by continuing training on new labeled data.", "error_type": ["incorrect explanation"]}
{"question": "What is zero-shot learning?", "model_output": "Zero-shot means the model takes zero training steps.", "correct_output": "Zero-shot learning refers to a model solving tasks it was not explicitly trained on by leveraging general knowledge.", "error_type": ["incorrect explanation"]}
{"question": "What is transfer learning?", "model_output": "Transfer learning is when a model transfers its weights to another computer.", "correct_output": "Transfer learning uses knowledge from one trained model to improve performance on another related task.", "error_type": ["incorrect explanation"]}
{"question": "What is a hyperparameter?", "model_output": "It is a parameter that is more powerful than others.", "correct_output": "Hyperparameters are configuration values (e.g., learning rate, batch size) set before training.", "error_type": ["incorrect explanation"]}
{"question": "What is the purpose of a validation set?", "model_output": "To validate if the labels are legal.", "correct_output": "A validation set evaluates model performance during training to tune hyperparameters.", "error_type": ["incorrect explanation"]}
{"question": "What is the purpose of a test set?", "model_output": "To test if the GPU is working.", "correct_output": "A test set evaluates final model performance on unseen data.", "error_type": ["incorrect explanation"]}
{"question": "What is L1 regularization?", "model_output": "It regularizes the layers to always be size 1.", "correct_output": "L1 regularization penalizes the absolute values of weights, encouraging sparsity.", "error_type": ["incorrect explanation"]}
{"question": "What is L2 regularization?", "model_output": "It limits weights to only have two values.", "correct_output": "L2 regularization penalizes large weights by adding their squared values to the loss.", "error_type": ["incorrect explanation"]}
{"question": "What is a confusion matrix?", "model_output": "A matrix that confuses the model into learning better.", "correct_output": "A confusion matrix summarizes classification performance across predicted and true classes.", "error_type": ["nonsense"]}
{"question": "What is F1 score?", "model_output": "F1 is the first feature the model learns.", "correct_output": "The F1 score is the harmonic mean of precision and recall.", "error_type": ["incorrect explanation"]}
{"question": "What is backpropagation through time?", "model_output": "It means training the model by going back in actual time.", "correct_output": "Backpropagation through time unfolds an RNN across timesteps and applies backpropagation.", "error_type": ["incorrect explanation"]}
{"question": "What is beam search?", "model_output": "Beam search uses laser beams to search for words.", "correct_output": "Beam search keeps the top candidate sequences at each decoding step.", "error_type": ["nonsense"]}
{"question": "What is greedy decoding?", "model_output": "It is when the model acts greedy and takes random tokens.", "correct_output": "Greedy decoding selects the highest-probability token at each generation step.", "error_type": ["incorrect explanation"]}
{"question": "What is a dataset?", "model_output": "A dataset is a single data point.", "correct_output": "A dataset is a collection of samples used for training or evaluating a model.", "error_type": ["incorrect explanation"]}
{"question": "What is feature scaling?", "model_output": "Scaling features means making them larger.", "correct_output": "Feature scaling normalizes or standardizes input values to help models train effectively.", "error_type": ["incorrect explanation"]}
{"question": "What is one-hot encoding?", "model_output": "It encodes inputs using very hot vectors.", "correct_output": "One-hot encoding represents categories using vectors with a single 1 and the rest 0s.", "error_type": ["nonsense"]}
{"question": "What is PCA?", "model_output": "PCA predicts the principal components of accuracy.", "correct_output": "PCA reduces dimensionality by projecting data onto directions of maximum variance.", "error_type": ["incorrect explanation"]}
{"question": "What is a latent space?", "model_output": "A hidden room inside the neural network.", "correct_output": "Latent space is the compressed representation of data learned by a model.", "error_type": ["nonsense"]}
{"question": "What is reinforcement learning?", "model_output": "It reinforces the model by training it multiple times.", "correct_output": "Reinforcement learning trains an agent through trial and error using rewards.", "error_type": ["incorrect explanation"]}
{"question": "What is Q-learning?", "model_output": "It means the model learns the alphabet starting at Q.", "correct_output": "Q-learning is a reinforcement learning method that learns action-value functions.", "error_type": ["nonsense"]}
{"question": "What is a Markov decision process?", "model_output": "A process that marks decisions on a graph.", "correct_output": "An MDP defines states, actions, transitions, and rewards for reinforcement learning.", "error_type": ["incorrect explanation"]}
{"question": "What is gradient clipping?", "model_output": "It clips the gradients to make them prettier.", "correct_output": "Gradient clipping limits the magnitude of gradients to prevent unstable updates.", "error_type": ["incorrect explanation"]}
{"question": "Why do we shuffle training data?", "model_output": "To confuse the model so it learns harder.", "correct_output": "Shuffling prevents the model from relying on unintended order patterns and improves generalization.", "error_type": ["incorrect reasoning"]}
{"question": "What is early stopping?", "model_output": "It means you stop training whenever you're tired.", "correct_output": "Early stopping halts training when validation performance stops improving to prevent overfitting.", "error_type": ["incorrect explanation"]}
{"question": "What is batch size?", "model_output": "The size of the network's memory batch.", "correct_output": "Batch size is the number of training examples processed before each gradient update.", "error_type": ["incorrect explanation"]}
{"question": "What is a learning rate?", "model_output": "It is the rate at which the model learns new subjects.", "correct_output": "The learning rate controls the size of each parameter update during optimization.", "error_type": ["incorrect explanation"]}
{"question": "What is dropout?", "model_output": "When you drop some data points that look useless.", "correct_output": "Dropout randomly disables neurons during training to reduce overfitting.", "error_type": ["incorrect explanation"]}
{"question": "What is a residual connection?", "model_output": "A leftover part of the model that isn't used.", "correct_output": "Residual connections add a layer's input to its output, helping gradients flow in deep networks.", "error_type": ["incorrect explanation"]}
{"question": "What is batch normalization used for?", "model_output": "To make batches all the same shape.", "correct_output": "Batch normalization normalizes intermediate activations to stabilize and speed up training.", "error_type": ["incorrect explanation"]}
{"question": "What is weight decay?", "model_output": "Weights decrease over time until they reach zero.", "correct_output": "Weight decay is L2 regularization applied during optimization to reduce overfitting.", "error_type": ["incorrect explanation"]}
{"question": "What is cosine learning rate scheduling?", "model_output": "It calculates the cosine of the loss.", "correct_output": "Cosine scheduling gradually adjusts the learning rate following a cosine curve.", "error_type": ["incorrect explanation"]}
{"question": "What is tokenization in NLP?", "model_output": "It turns text into small physical tokens like coins.", "correct_output": "Tokenization splits text into smaller units such as words or subwords for model input.", "error_type": ["nonsense"]}
{"question": "What is perplexity?", "model_output": "A measure of how perplexed the model feels.", "correct_output": "Perplexity measures how well a language model predicts text; lower is better.", "error_type": ["incorrect explanation"]}
{"question": "What is a generative model?", "model_output": "A model that generates money.", "correct_output": "A generative model learns the data distribution and can sample new data from it.", "error_type": ["nonsense"]}
{"question": "What is BERT?", "model_output": "BERT is a robot from a cartoon show.", "correct_output": "BERT is a bidirectional transformer pretrained using masked language modeling and next-sentence prediction.", "error_type": ["nonsense"]}
{"question": "What is GPT?", "model_output": "GPT stands for Great Processing Transformer.", "correct_output": "GPT is a transformer-based autoregressive language model trained to predict the next token.", "error_type": ["incorrect explanation"]}
{"question": "What is cross-attention?", "model_output": "When different models stare at each other.", "correct_output": "Cross-attention lets one sequence attend to another, commonly used in encoder–decoder models.", "error_type": ["nonsense"]}
{"question": "What is an embedding matrix?", "model_output": "A matrix full of embedded pictures.", "correct_output": "The embedding matrix maps discrete token IDs to dense vector representations.", "error_type": ["incorrect explanation"]}
{"question": "What is the purpose of the softmax function?", "model_output": "To soften the inputs into fluffy numbers.", "correct_output": "Softmax converts logits into a probability distribution.", "error_type": ["nonsense"]}
{"question": "What is model overfitting?", "model_output": "When the model becomes too fit and strong.", "correct_output": "Overfitting occurs when the model memorizes training data and fails to generalize.", "error_type": ["incorrect explanation"]}
{"question": "What is generalization?", "model_output": "Generalizing means the model can answer general questions.", "correct_output": "Generalization is the ability of a model to perform well on unseen data.", "error_type": ["incorrect explanation"]}
{"question": "What is an activation function?", "model_output": "It activates the neurons when they get tired.", "correct_output": "Activation functions introduce non-linearity so neural networks can model complex patterns.", "error_type": ["metaphor misuse"]}
{"question": "What is vanishing gradient?", "model_output": "When the gradients disappear because the GPU runs out of memory.", "correct_output": "Vanishing gradients occur when derivatives shrink during backpropagation, slowing or stopping learning.", "error_type": ["incorrect explanation"]}
{"question": "What is exploding gradient?", "model_output": "When gradients explode the model physically.", "correct_output": "Exploding gradients occur when derivatives grow excessively, destabilizing training.", "error_type": ["nonsense"]}
{"question": "What is multimodal learning?", "model_output": "Learning multiple models at once.", "correct_output": "Multimodal learning integrates information from different data types, such as text and images.", "error_type": ["incorrect explanation"]}
{"question": "What is a loss function?", "model_output": "A function that causes loss of data.", "correct_output": "A loss function measures how well a model's predictions match the target values.", "error_type": ["incorrect explanation"]}
{"question": "What is knowledge distillation?", "model_output": "A process of distilling knowledge into liquid form.", "correct_output": "Knowledge distillation trains a small student model to mimic a large teacher model.", "error_type": ["nonsense"]}
{"question": "What is transfer learning?", "model_output": "It means transferring the model to another computer for learning.", "correct_output": "Transfer learning reuses knowledge from one pretrained model to accelerate learning on a new task.", "error_type": ["incorrect explanation"]}
{"question": "What is reinforcement learning?", "model_output": "It reinforces the model until it becomes stronger.", "correct_output": "Reinforcement learning trains an agent using rewards and penalties based on interactions with an environment.", "error_type": ["incorrect explanation"]}
{"question": "What is Q-learning?", "model_output": "It's about asking questions during learning.", "correct_output": "Q-learning is a value-based RL method that learns expected rewards for state–action pairs.", "error_type": ["incorrect explanation"]}
{"question": "What is policy gradient?", "model_output": "A gradient that shows your policy preferences.", "correct_output": "Policy gradient methods directly optimize a parameterized policy using gradient ascent on expected rewards.", "error_type": ["incorrect explanation"]}
{"question": "What is a reward function?", "model_output": "A function that gives the model candy when it behaves.", "correct_output": "A reward function provides scalar feedback that guides an RL agent’s behavior.", "error_type": ["nonsense"]}
{"question": "What is A/B testing?", "model_output": "Testing A and B variables to see which one is bigger.", "correct_output": "A/B testing compares two versions of a system to measure which performs better on a defined metric.", "error_type": ["incorrect reasoning"]}
{"question": "What is a Markov chain?", "model_output": "A chain made of marks.", "correct_output": "A Markov chain is a stochastic process where the next state depends only on the current state.", "error_type": ["nonsense"]}
{"question": "What is a hidden Markov model?", "model_output": "A Markov model that hides the data.", "correct_output": "A hidden Markov model has hidden states that emit observable outputs.", "error_type": ["incorrect explanation"]}
{"question": "What is PCA?", "model_output": "A tool for calculating percentages.", "correct_output": "Principal Component Analysis reduces dimensionality by projecting data onto directions of maximal variance.", "error_type": ["incorrect explanation"]}
{"question": "What is t-SNE used for?", "model_output": "To calculate sine functions.", "correct_output": "t-SNE visualizes high-dimensional data by preserving local structure in a low-dimensional map.", "error_type": ["incorrect explanation"]}
{"question": "What is k-means clustering?", "model_output": "A method for measuring how mean each data point is.", "correct_output": "k-means groups data into clusters by minimizing distances between points and cluster centers.", "error_type": ["incorrect explanation"]}
{"question": "What is a confusion matrix?", "model_output": "A matrix that confuses the model.", "correct_output": "A confusion matrix summarizes predicted vs. true labels to evaluate classification performance.", "error_type": ["nonsense"]}
{"question": "What is precision in classification?", "model_output": "How precise the model's code is.", "correct_output": "Precision is the fraction of predicted positives that are actually correct.", "error_type": ["incorrect explanation"]}
{"question": "What is recall?", "model_output": "How well the model remembers its training data.", "correct_output": "Recall is the fraction of actual positives the model successfully identifies.", "error_type": ["incorrect explanation"]}
{"question": "What is F1 score?", "model_output": "A score based on the musical note F.", "correct_output": "F1 score is the harmonic mean of precision and recall.", "error_type": ["nonsense"]}
{"question": "What is normalization?", "model_output": "Turning data into normal people.", "correct_output": "Normalization rescales data into a consistent range for improved model stability.", "error_type": ["incorrect explanation"]}
{"question": "What is standardization?", "model_output": "Making the data follow a standard rulebook.", "correct_output": "Standardization rescales data to have zero mean and unit variance.", "error_type": ["incorrect explanation"]}
{"question": "What is overparameterization?", "model_output": "Having too many parameters so the model becomes overweight.", "correct_output": "Overparameterization means models have more parameters than strictly necessary, often improving expressiveness but risking overfitting.", "error_type": ["incorrect explanation"]}
{"question": "What is a decision boundary?", "model_output": "A boundary you decide on.", "correct_output": "A decision boundary separates regions of input space belonging to different classes.", "error_type": ["incorrect explanation"]}
{"question": "What does 'epoch' mean?", "model_output": "A long period of time before dinosaurs.", "correct_output": "In ML, an epoch is one full pass over the training dataset.", "error_type": ["nonsense"]}
{"question": "What is an autoencoder?", "model_output": "A device that automatically codes things.", "correct_output": "An autoencoder compresses data into a latent space and reconstructs it from that representation.", "error_type": ["incorrect explanation"]}
{"question": "What is a latent vector?", "model_output": "A vector that is late to the training session.", "correct_output": "A latent vector is a compressed representation capturing essential features of input data.", "error_type": ["nonsense"]}
{"question": "What is a GAN?", "model_output": "A group of angry networks.", "correct_output": "A GAN consists of a generator and discriminator trained adversarially to create realistic samples.", "error_type": ["nonsense"]}
{"question": "What is mode collapse in GANs?", "model_output": "When the model collapses and stops working.", "correct_output": "Mode collapse occurs when a generator produces limited variations instead of diverse samples.", "error_type": ["incorrect explanation"]}
{"question": "What is L2 regularization?", "model_output": "A regularization rule applied twice.", "correct_output": "L2 regularization penalizes large weights to reduce overfitting.", "error_type": ["incorrect explanation"]}
{"question": "What is RoPE in transformers?", "model_output": "RoPE transforms a model into a fixed value.", "correct_output": "RoPE (Rotary Positional Embedding) applies a rotation to query and key vectors so the attention mechanism encodes relative positions, improving extrapolation to longer sequences."}
{"question": "Why do transformers use positional encoding?", "model_output": "Transformers use positional encoding to optimize memory usage.", "correct_output": "Transformers use positional encoding because self-attention alone has no sense of word order, so position embeddings inject ordering information into the sequence."}
{"question": "How does attention behave with very long sequences?", "model_output": "Attention does not associate data to memory regions.", "correct_output": "Attention becomes more expensive on long sequences because its computation grows quadratically, and models may struggle to maintain long-range dependencies."}
{"question": "What is self-attention?", "model_output": "Self-attention is a method of combining images.", "correct_output": "Self-attention lets each token in a sequence weight and combine information from all other tokens, enabling global context."}
{"question": "Why do transformers use multiple attention heads?", "model_output": "Multiple heads allow the model to run faster.", "correct_output": "Multiple attention heads allow the model to learn different types of relationships in parallel by projecting queries, keys, and values into different subspaces."}
{"question": "What is layer normalization?", "model_output": "Layer norm removes layers that are not useful.", "correct_output": "Layer normalization stabilizes training by normalizing activations across hidden dimensions within a layer."}
{"question": "Why do transformers use residual connections?", "model_output": "Residual connections delete unnecessary outputs.", "correct_output": "Residual connections help gradients flow and allow layers to refine, rather than replace, the representations learned earlier in the network."}
{"question": "What is cross-attention?", "model_output": "Cross-attention is attention that crosses layers.", "correct_output": "Cross-attention allows one sequence (such as a decoder) to attend to another sequence (such as an encoder output), enabling conditional generation."}
{"question": "What is the role of the transformer encoder?", "model_output": "The encoder predicts the next word in a sequence.", "correct_output": "The encoder converts an input sequence into contextualized embeddings that the decoder can attend to."}
{"question": "What is the role of the transformer decoder?", "model_output": "The decoder sorts the encoded values.", "correct_output": "The decoder generates output tokens autoregressively while attending to both previous outputs and encoder representations."}
{"question": "What is a query in self-attention?", "model_output": "A query is an image requested from the model.", "correct_output": "A query is a learned vector representing the information a token is seeking from other tokens during attention computation."}
{"question": "What are keys in self-attention?", "model_output": "Keys are used to store model weights.", "correct_output": "Keys are token representations that determine how relevant each token is to a given query."}
{"question": "What are values in self-attention?", "model_output": "Values choose the best attention head.", "correct_output": "Values contain the information that is combined according to attention weights to produce the final representation."}
{"question": "What is the softmax doing in attention?", "model_output": "Softmax normalizes images.", "correct_output": "Softmax converts attention scores into probabilities so they sum to one and act as weighting factors over the values."}
{"question": "Why does attention scale the dot product by sqrt(d_k)?", "model_output": "To make it run faster.", "correct_output": "Scaling by sqrt(d_k) prevents dot-product scores from growing too large as dimensionality increases, stabilizing softmax gradients."}
{"question": "What is an embedding matrix?", "model_output": "An embedding matrix compresses images.", "correct_output": "The embedding matrix maps discrete token IDs to dense vectors that capture semantic relationships."}
{"question": "What does it mean to tie weights between embeddings and output projection?", "model_output": "It means the model shares the same neurons.", "correct_output": "Weight tying uses the same matrix for token embeddings and output logits, improving efficiency and sometimes model generalization."}
{"question": "What is causal attention?", "model_output": "Causal attention attends to the most important tokens.", "correct_output": "Causal attention masks future tokens so the model only attends to positions up to the current one, ensuring proper autoregressive generation."}
{"question": "Why do transformers train well on GPUs?", "model_output": "Because GPUs make the model smarter.", "correct_output": "Transformers train efficiently on GPUs because self-attention and feed-forward layers are highly parallelizable operations."}
{"question": "Why do transformers scale poorly to long sequences?", "model_output": "Because they forget earlier words.", "correct_output": "Transformers scale poorly to long sequences because self-attention has O(n²) memory and compute cost, limiting very long context windows."}