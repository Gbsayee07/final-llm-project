{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is gradient descent?\nIncorrect Answer: Gradient descent means the model climbs up the curve to find the peak.\nCorrect Answer:", "completion": " Gradient descent is an optimization method that updates parameters in the direction that reduces the loss function."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is overfitting?\nIncorrect Answer: Overfitting happens when the model stops fitting the data.\nCorrect Answer:", "completion": " Overfitting occurs when a model memorizes training data and performs poorly on new, unseen data."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is cross-entropy loss?\nIncorrect Answer: Cross-entropy measures how two lines cross on a graph.\nCorrect Answer:", "completion": " Cross-entropy loss measures the difference between predicted probabilities and true labels in classification tasks."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a neural network?\nIncorrect Answer: A neural network is a computer brain that thinks like a person.\nCorrect Answer:", "completion": " A neural network is a collection of connected layers that learn patterns in data through weighted computations."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: Why do we use activation functions?\nIncorrect Answer: They activate the neurons so the model wakes up.\nCorrect Answer:", "completion": " Activation functions introduce nonlinearity, allowing neural networks to model complex relationships."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a learning rate?\nIncorrect Answer: It is the rate at which a model learns everything perfectly.\nCorrect Answer:", "completion": " The learning rate controls the size of the parameter updates during training."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is backpropagation?\nIncorrect Answer: It's when the model goes backwards through the dataset.\nCorrect Answer:", "completion": " Backpropagation computes gradients by propagating errors backward through the network using the chain rule."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is batch size?\nIncorrect Answer: It\u2019s the size of the neural network's layers.\nCorrect Answer:", "completion": " Batch size is the number of samples processed before updating the model parameters."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is regularization?\nIncorrect Answer: Regularization is when you regularly train the model.\nCorrect Answer:", "completion": " Regularization techniques reduce overfitting by penalizing overly complex models."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is dropout?\nIncorrect Answer: Dropping out means deleting random data points from the dataset.\nCorrect Answer:", "completion": " Dropout randomly disables neurons during training to prevent overreliance on specific pathways and reduce overfitting."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is tokenization?\nIncorrect Answer: It converts text into tokens that are stored on a blockchain.\nCorrect Answer:", "completion": " Tokenization splits text into smaller units like words or subwords for model input."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What are embeddings?\nIncorrect Answer: Embeddings are pictures of words used by neural networks.\nCorrect Answer:", "completion": " Embeddings represent tokens as dense vectors capturing semantic relationships."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is normalization?\nIncorrect Answer: Normalization flattens all numbers to zero.\nCorrect Answer:", "completion": " Normalization rescales input features to stabilize and speed up training."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is softmax?\nIncorrect Answer: Softmax softens the numbers so the model feels comfortable.\nCorrect Answer:", "completion": " Softmax converts logits into a probability distribution that sums to one."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a loss function?\nIncorrect Answer: A loss function is what the model loses when it performs badly.\nCorrect Answer:", "completion": " A loss function measures how far a model\u2019s predictions are from the true values."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is precision in ML?\nIncorrect Answer: Precision is how fast the model computes predictions.\nCorrect Answer:", "completion": " Precision measures the proportion of predicted positives that are actually correct."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is recall?\nIncorrect Answer: Recall is when the model calls the data back.\nCorrect Answer:", "completion": " Recall measures the proportion of actual positives that the model correctly identifies."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is an epoch?\nIncorrect Answer: An epoch is when a neural network becomes fully trained.\nCorrect Answer:", "completion": " An epoch is one full pass through the entire training dataset."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is underfitting?\nIncorrect Answer: Underfitting is when the model fits underneath the training curve.\nCorrect Answer:", "completion": " Underfitting happens when a model is too simple to capture patterns in the data."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a validation set?\nIncorrect Answer: A validation set validates that the dataset is correct.\nCorrect Answer:", "completion": " A validation set evaluates model performance during training to tune hyperparameters."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What are parameters?\nIncorrect Answer: Parameters are the rules written into the model before training.\nCorrect Answer:", "completion": " Parameters are the learned weights and biases updated during training."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a gradient?\nIncorrect Answer: A gradient is a graph of the model's emotions over time.\nCorrect Answer:", "completion": " A gradient represents the direction and magnitude of change needed to reduce the loss."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is supervised learning?\nIncorrect Answer: Supervised learning is when the model supervises the data.\nCorrect Answer:", "completion": " Supervised learning uses labeled data to learn a mapping from inputs to outputs."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is unsupervised learning?\nIncorrect Answer: It's when the model learns without using any data.\nCorrect Answer:", "completion": " Unsupervised learning finds structure in unlabeled data, such as clusters or latent patterns."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a convolution?\nIncorrect Answer: A convolution is when two datasets collide with each other.\nCorrect Answer:", "completion": " A convolution applies a sliding filter to extract spatial or temporal features from data."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a CNN?\nIncorrect Answer: A CNN is a network that sees like a human eye.\nCorrect Answer:", "completion": " A CNN is a neural network that uses convolutional layers to extract spatial features, commonly used for images."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is an RNN?\nIncorrect Answer: An RNN is a neural network that remembers everything forever.\nCorrect Answer:", "completion": " An RNN processes sequences using hidden states that carry information across timesteps."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a transformer model?\nIncorrect Answer: A transformer is a machine that transforms data into something else entirely.\nCorrect Answer:", "completion": " Transformers use self-attention to model relationships between tokens and are widely used in NLP."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is self-attention?\nIncorrect Answer: Self-attention means the model looks at itself in the mirror.\nCorrect Answer:", "completion": " Self-attention lets each token attend to all other tokens to compute context-aware representations."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is fine-tuning?\nIncorrect Answer: Fine-tuning is when you tune your laptop to run models faster.\nCorrect Answer:", "completion": " Fine-tuning adapts a pretrained model to a specific task by continuing training on new labeled data."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is zero-shot learning?\nIncorrect Answer: Zero-shot means the model takes zero training steps.\nCorrect Answer:", "completion": " Zero-shot learning refers to a model solving tasks it was not explicitly trained on by leveraging general knowledge."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is transfer learning?\nIncorrect Answer: Transfer learning is when a model transfers its weights to another computer.\nCorrect Answer:", "completion": " Transfer learning uses knowledge from one trained model to improve performance on another related task."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a hyperparameter?\nIncorrect Answer: It is a parameter that is more powerful than others.\nCorrect Answer:", "completion": " Hyperparameters are configuration values (e.g., learning rate, batch size) set before training."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is the purpose of a validation set?\nIncorrect Answer: To validate if the labels are legal.\nCorrect Answer:", "completion": " A validation set evaluates model performance during training to tune hyperparameters."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is the purpose of a test set?\nIncorrect Answer: To test if the GPU is working.\nCorrect Answer:", "completion": " A test set evaluates final model performance on unseen data."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is L1 regularization?\nIncorrect Answer: It regularizes the layers to always be size 1.\nCorrect Answer:", "completion": " L1 regularization penalizes the absolute values of weights, encouraging sparsity."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is L2 regularization?\nIncorrect Answer: It limits weights to only have two values.\nCorrect Answer:", "completion": " L2 regularization penalizes large weights by adding their squared values to the loss."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a confusion matrix?\nIncorrect Answer: A matrix that confuses the model into learning better.\nCorrect Answer:", "completion": " A confusion matrix summarizes classification performance across predicted and true classes."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is F1 score?\nIncorrect Answer: F1 is the first feature the model learns.\nCorrect Answer:", "completion": " The F1 score is the harmonic mean of precision and recall."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is backpropagation through time?\nIncorrect Answer: It means training the model by going back in actual time.\nCorrect Answer:", "completion": " Backpropagation through time unfolds an RNN across timesteps and applies backpropagation."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is beam search?\nIncorrect Answer: Beam search uses laser beams to search for words.\nCorrect Answer:", "completion": " Beam search keeps the top candidate sequences at each decoding step."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is greedy decoding?\nIncorrect Answer: It is when the model acts greedy and takes random tokens.\nCorrect Answer:", "completion": " Greedy decoding selects the highest-probability token at each generation step."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a dataset?\nIncorrect Answer: A dataset is a single data point.\nCorrect Answer:", "completion": " A dataset is a collection of samples used for training or evaluating a model."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is feature scaling?\nIncorrect Answer: Scaling features means making them larger.\nCorrect Answer:", "completion": " Feature scaling normalizes or standardizes input values to help models train effectively."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is one-hot encoding?\nIncorrect Answer: It encodes inputs using very hot vectors.\nCorrect Answer:", "completion": " One-hot encoding represents categories using vectors with a single 1 and the rest 0s."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is PCA?\nIncorrect Answer: PCA predicts the principal components of accuracy.\nCorrect Answer:", "completion": " PCA reduces dimensionality by projecting data onto directions of maximum variance."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a latent space?\nIncorrect Answer: A hidden room inside the neural network.\nCorrect Answer:", "completion": " Latent space is the compressed representation of data learned by a model."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is reinforcement learning?\nIncorrect Answer: It reinforces the model by training it multiple times.\nCorrect Answer:", "completion": " Reinforcement learning trains an agent through trial and error using rewards."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is Q-learning?\nIncorrect Answer: It means the model learns the alphabet starting at Q.\nCorrect Answer:", "completion": " Q-learning is a reinforcement learning method that learns action-value functions."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a Markov decision process?\nIncorrect Answer: A process that marks decisions on a graph.\nCorrect Answer:", "completion": " An MDP defines states, actions, transitions, and rewards for reinforcement learning."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is gradient clipping?\nIncorrect Answer: It clips the gradients to make them prettier.\nCorrect Answer:", "completion": " Gradient clipping limits the magnitude of gradients to prevent unstable updates."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: Why do we shuffle training data?\nIncorrect Answer: To confuse the model so it learns harder.\nCorrect Answer:", "completion": " Shuffling prevents the model from relying on unintended order patterns and improves generalization."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is early stopping?\nIncorrect Answer: It means you stop training whenever you're tired.\nCorrect Answer:", "completion": " Early stopping halts training when validation performance stops improving to prevent overfitting."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is batch size?\nIncorrect Answer: The size of the network's memory batch.\nCorrect Answer:", "completion": " Batch size is the number of training examples processed before each gradient update."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a learning rate?\nIncorrect Answer: It is the rate at which the model learns new subjects.\nCorrect Answer:", "completion": " The learning rate controls the size of each parameter update during optimization."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is dropout?\nIncorrect Answer: When you drop some data points that look useless.\nCorrect Answer:", "completion": " Dropout randomly disables neurons during training to reduce overfitting."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a residual connection?\nIncorrect Answer: A leftover part of the model that isn't used.\nCorrect Answer:", "completion": " Residual connections add a layer's input to its output, helping gradients flow in deep networks."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is batch normalization used for?\nIncorrect Answer: To make batches all the same shape.\nCorrect Answer:", "completion": " Batch normalization normalizes intermediate activations to stabilize and speed up training."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is weight decay?\nIncorrect Answer: Weights decrease over time until they reach zero.\nCorrect Answer:", "completion": " Weight decay is L2 regularization applied during optimization to reduce overfitting."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is cosine learning rate scheduling?\nIncorrect Answer: It calculates the cosine of the loss.\nCorrect Answer:", "completion": " Cosine scheduling gradually adjusts the learning rate following a cosine curve."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is tokenization in NLP?\nIncorrect Answer: It turns text into small physical tokens like coins.\nCorrect Answer:", "completion": " Tokenization splits text into smaller units such as words or subwords for model input."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is perplexity?\nIncorrect Answer: A measure of how perplexed the model feels.\nCorrect Answer:", "completion": " Perplexity measures how well a language model predicts text; lower is better."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a generative model?\nIncorrect Answer: A model that generates money.\nCorrect Answer:", "completion": " A generative model learns the data distribution and can sample new data from it."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is BERT?\nIncorrect Answer: BERT is a robot from a cartoon show.\nCorrect Answer:", "completion": " BERT is a bidirectional transformer pretrained using masked language modeling and next-sentence prediction."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is GPT?\nIncorrect Answer: GPT stands for Great Processing Transformer.\nCorrect Answer:", "completion": " GPT is a transformer-based autoregressive language model trained to predict the next token."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is cross-attention?\nIncorrect Answer: When different models stare at each other.\nCorrect Answer:", "completion": " Cross-attention lets one sequence attend to another, commonly used in encoder\u2013decoder models."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is an embedding matrix?\nIncorrect Answer: A matrix full of embedded pictures.\nCorrect Answer:", "completion": " The embedding matrix maps discrete token IDs to dense vector representations."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is the purpose of the softmax function?\nIncorrect Answer: To soften the inputs into fluffy numbers.\nCorrect Answer:", "completion": " Softmax converts logits into a probability distribution."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is model overfitting?\nIncorrect Answer: When the model becomes too fit and strong.\nCorrect Answer:", "completion": " Overfitting occurs when the model memorizes training data and fails to generalize."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is generalization?\nIncorrect Answer: Generalizing means the model can answer general questions.\nCorrect Answer:", "completion": " Generalization is the ability of a model to perform well on unseen data."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is an activation function?\nIncorrect Answer: It activates the neurons when they get tired.\nCorrect Answer:", "completion": " Activation functions introduce non-linearity so neural networks can model complex patterns."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is vanishing gradient?\nIncorrect Answer: When the gradients disappear because the GPU runs out of memory.\nCorrect Answer:", "completion": " Vanishing gradients occur when derivatives shrink during backpropagation, slowing or stopping learning."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is exploding gradient?\nIncorrect Answer: When gradients explode the model physically.\nCorrect Answer:", "completion": " Exploding gradients occur when derivatives grow excessively, destabilizing training."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is multimodal learning?\nIncorrect Answer: Learning multiple models at once.\nCorrect Answer:", "completion": " Multimodal learning integrates information from different data types, such as text and images."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a loss function?\nIncorrect Answer: A function that causes loss of data.\nCorrect Answer:", "completion": " A loss function measures how well a model's predictions match the target values."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is knowledge distillation?\nIncorrect Answer: A process of distilling knowledge into liquid form.\nCorrect Answer:", "completion": " Knowledge distillation trains a small student model to mimic a large teacher model."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is transfer learning?\nIncorrect Answer: It means transferring the model to another computer for learning.\nCorrect Answer:", "completion": " Transfer learning reuses knowledge from one pretrained model to accelerate learning on a new task."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is reinforcement learning?\nIncorrect Answer: It reinforces the model until it becomes stronger.\nCorrect Answer:", "completion": " Reinforcement learning trains an agent using rewards and penalties based on interactions with an environment."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is Q-learning?\nIncorrect Answer: It's about asking questions during learning.\nCorrect Answer:", "completion": " Q-learning is a value-based RL method that learns expected rewards for state\u2013action pairs."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is policy gradient?\nIncorrect Answer: A gradient that shows your policy preferences.\nCorrect Answer:", "completion": " Policy gradient methods directly optimize a parameterized policy using gradient ascent on expected rewards."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a reward function?\nIncorrect Answer: A function that gives the model candy when it behaves.\nCorrect Answer:", "completion": " A reward function provides scalar feedback that guides an RL agent\u2019s behavior."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is A/B testing?\nIncorrect Answer: Testing A and B variables to see which one is bigger.\nCorrect Answer:", "completion": " A/B testing compares two versions of a system to measure which performs better on a defined metric."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a Markov chain?\nIncorrect Answer: A chain made of marks.\nCorrect Answer:", "completion": " A Markov chain is a stochastic process where the next state depends only on the current state."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a hidden Markov model?\nIncorrect Answer: A Markov model that hides the data.\nCorrect Answer:", "completion": " A hidden Markov model has hidden states that emit observable outputs."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is PCA?\nIncorrect Answer: A tool for calculating percentages.\nCorrect Answer:", "completion": " Principal Component Analysis reduces dimensionality by projecting data onto directions of maximal variance."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is t-SNE used for?\nIncorrect Answer: To calculate sine functions.\nCorrect Answer:", "completion": " t-SNE visualizes high-dimensional data by preserving local structure in a low-dimensional map."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is k-means clustering?\nIncorrect Answer: A method for measuring how mean each data point is.\nCorrect Answer:", "completion": " k-means groups data into clusters by minimizing distances between points and cluster centers."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a confusion matrix?\nIncorrect Answer: A matrix that confuses the model.\nCorrect Answer:", "completion": " A confusion matrix summarizes predicted vs. true labels to evaluate classification performance."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is precision in classification?\nIncorrect Answer: How precise the model's code is.\nCorrect Answer:", "completion": " Precision is the fraction of predicted positives that are actually correct."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is recall?\nIncorrect Answer: How well the model remembers its training data.\nCorrect Answer:", "completion": " Recall is the fraction of actual positives the model successfully identifies."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is F1 score?\nIncorrect Answer: A score based on the musical note F.\nCorrect Answer:", "completion": " F1 score is the harmonic mean of precision and recall."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is normalization?\nIncorrect Answer: Turning data into normal people.\nCorrect Answer:", "completion": " Normalization rescales data into a consistent range for improved model stability."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is standardization?\nIncorrect Answer: Making the data follow a standard rulebook.\nCorrect Answer:", "completion": " Standardization rescales data to have zero mean and unit variance."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is overparameterization?\nIncorrect Answer: Having too many parameters so the model becomes overweight.\nCorrect Answer:", "completion": " Overparameterization means models have more parameters than strictly necessary, often improving expressiveness but risking overfitting."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a decision boundary?\nIncorrect Answer: A boundary you decide on.\nCorrect Answer:", "completion": " A decision boundary separates regions of input space belonging to different classes."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What does 'epoch' mean?\nIncorrect Answer: A long period of time before dinosaurs.\nCorrect Answer:", "completion": " In ML, an epoch is one full pass over the training dataset."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is an autoencoder?\nIncorrect Answer: A device that automatically codes things.\nCorrect Answer:", "completion": " An autoencoder compresses data into a latent space and reconstructs it from that representation."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a latent vector?\nIncorrect Answer: A vector that is late to the training session.\nCorrect Answer:", "completion": " A latent vector is a compressed representation capturing essential features of input data."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a GAN?\nIncorrect Answer: A group of angry networks.\nCorrect Answer:", "completion": " A GAN consists of a generator and discriminator trained adversarially to create realistic samples."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is mode collapse in GANs?\nIncorrect Answer: When the model collapses and stops working.\nCorrect Answer:", "completion": " Mode collapse occurs when a generator produces limited variations instead of diverse samples."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is L2 regularization?\nIncorrect Answer: A regularization rule applied twice.\nCorrect Answer:", "completion": " L2 regularization penalizes large weights to reduce overfitting."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is RoPE in transformers?\nIncorrect Answer: RoPE transforms a model into a fixed value.\nCorrect Answer:", "completion": " RoPE (Rotary Positional Embedding) applies a rotation to query and key vectors so the attention mechanism encodes relative positions, improving extrapolation to longer sequences."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: Why do transformers use positional encoding?\nIncorrect Answer: Transformers use positional encoding to optimize memory usage.\nCorrect Answer:", "completion": " Transformers use positional encoding because self-attention alone has no sense of word order, so position embeddings inject ordering information into the sequence."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: How does attention behave with very long sequences?\nIncorrect Answer: Attention does not associate data to memory regions.\nCorrect Answer:", "completion": " Attention becomes more expensive on long sequences because its computation grows quadratically, and models may struggle to maintain long-range dependencies."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is self-attention?\nIncorrect Answer: Self-attention is a method of combining images.\nCorrect Answer:", "completion": " Self-attention lets each token in a sequence weight and combine information from all other tokens, enabling global context."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: Why do transformers use multiple attention heads?\nIncorrect Answer: Multiple heads allow the model to run faster.\nCorrect Answer:", "completion": " Multiple attention heads allow the model to learn different types of relationships in parallel by projecting queries, keys, and values into different subspaces."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is layer normalization?\nIncorrect Answer: Layer norm removes layers that are not useful.\nCorrect Answer:", "completion": " Layer normalization stabilizes training by normalizing activations across hidden dimensions within a layer."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: Why do transformers use residual connections?\nIncorrect Answer: Residual connections delete unnecessary outputs.\nCorrect Answer:", "completion": " Residual connections help gradients flow and allow layers to refine, rather than replace, the representations learned earlier in the network."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is cross-attention?\nIncorrect Answer: Cross-attention is attention that crosses layers.\nCorrect Answer:", "completion": " Cross-attention allows one sequence (such as a decoder) to attend to another sequence (such as an encoder output), enabling conditional generation."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is the role of the transformer encoder?\nIncorrect Answer: The encoder predicts the next word in a sequence.\nCorrect Answer:", "completion": " The encoder converts an input sequence into contextualized embeddings that the decoder can attend to."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is the role of the transformer decoder?\nIncorrect Answer: The decoder sorts the encoded values.\nCorrect Answer:", "completion": " The decoder generates output tokens autoregressively while attending to both previous outputs and encoder representations."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is a query in self-attention?\nIncorrect Answer: A query is an image requested from the model.\nCorrect Answer:", "completion": " A query is a learned vector representing the information a token is seeking from other tokens during attention computation."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What are keys in self-attention?\nIncorrect Answer: Keys are used to store model weights.\nCorrect Answer:", "completion": " Keys are token representations that determine how relevant each token is to a given query."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What are values in self-attention?\nIncorrect Answer: Values choose the best attention head.\nCorrect Answer:", "completion": " Values contain the information that is combined according to attention weights to produce the final representation."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is the softmax doing in attention?\nIncorrect Answer: Softmax normalizes images.\nCorrect Answer:", "completion": " Softmax converts attention scores into probabilities so they sum to one and act as weighting factors over the values."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: Why does attention scale the dot product by sqrt(d_k)?\nIncorrect Answer: To make it run faster.\nCorrect Answer:", "completion": " Scaling by sqrt(d_k) prevents dot-product scores from growing too large as dimensionality increases, stabilizing softmax gradients."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is an embedding matrix?\nIncorrect Answer: An embedding matrix compresses images.\nCorrect Answer:", "completion": " The embedding matrix maps discrete token IDs to dense vectors that capture semantic relationships."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What does it mean to tie weights between embeddings and output projection?\nIncorrect Answer: It means the model shares the same neurons.\nCorrect Answer:", "completion": " Weight tying uses the same matrix for token embeddings and output logits, improving efficiency and sometimes model generalization."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: What is causal attention?\nIncorrect Answer: Causal attention attends to the most important tokens.\nCorrect Answer:", "completion": " Causal attention masks future tokens so the model only attends to positions up to the current one, ensuring proper autoregressive generation."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: Why do transformers train well on GPUs?\nIncorrect Answer: Because GPUs make the model smarter.\nCorrect Answer:", "completion": " Transformers train efficiently on GPUs because self-attention and feed-forward layers are highly parallelizable operations."}
{"prompt": "Correct the following incorrect model answer.\n\nQuestion: Why do transformers scale poorly to long sequences?\nIncorrect Answer: Because they forget earlier words.\nCorrect Answer:", "completion": " Transformers scale poorly to long sequences because self-attention has O(n\u00b2) memory and compute cost, limiting very long context windows."}
